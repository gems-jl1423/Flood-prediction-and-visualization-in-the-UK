{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any group that might take this task over in the future, there are a few ideas we had that we did not have enough time to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fixing scoring issue with historic flooding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the historic flooding method correctly runs in a notebook (see code below), it is throwing errors with the given tests. We are confident in the model's functionality and its outputs are used in visualization. Still, a future group might want to spend some time debugging to make sure it passes the tests as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flood_tool as ft\n",
    "from flood_tool.tool import*\n",
    "from flood_tool.geo import * \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring.test_scorable import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training historic_rf\n"
     ]
    }
   ],
   "source": [
    "test_predict_historic_flooding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = Tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training historic_rf\n"
     ]
    }
   ],
   "source": [
    "model = tool.train(historic_flooding_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training historic_rf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M34 7QL     False\n",
       "OL4 3NQ     False\n",
       "B36 8TE     False\n",
       "NE16 3AT    False\n",
       "WS10 8DE    False\n",
       "            ...  \n",
       "NN9 7TY     False\n",
       "HU6 7YG     False\n",
       "LS12 1DY    False\n",
       "DN4 6TZ     False\n",
       "S31 9BD     False\n",
       "Name: historicallyFlooded, Length: 10000, dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.predict_historic_flooding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when we went back to versions of historic_flooding that had passed and received scores from James in previous days, we could not avoid the errors. We could not wrap our heads around the scoring and since this method has received scores in the past days and functions as we expect when tested in the notebook, we are comfortable passing it on. \n",
    "\n",
    "Still, if given more time, another group might want to try to wrap their heads around the scoring and make sure it works there too. \n",
    "\n",
    "**Note**: The scoring DOES work on our end for all other models, even though some of them were throwing errors on James' system as recently as 23/11. Hopefully these errors are fixed in the final push, but if not, we want to mention it could be another weird hardware issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualizing by different geographic levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our methods for question 6 (predict_total_value and predict_annual_flood_risk) take in a geographic level and output the collated information based on that scale. We originally wanted to give a way to visualize this information, with tick boxes, so the user could choose the geographic scale they wanted. We were not able to complete this, so it could be a task for the next group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Better handling imbalance of dataset in median house prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median house prices skewed towards the middle. There were very few prices that were quite high or quite low, making predicting those that are high and low difficult. In a next iteration of this project, we would explore more ways to balance this data and better control for those high and low houses. We might consider developing different models for different datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. More sophisticated way of geographically clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several local authorities have low scores, so we would have liked to better optimize this, or combine the local authorities into categories like high risk and low risk areas. Ideas for optimization: customized model for each local authority or merging local authorities with each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Improve Krigging method to incorporate denser dataset of postcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset of postcodes to create a more balanced dataset. Currently the risk level is low, so we need to sample. It would be helful to split the risk levels in different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Optimize computing time of Kregging method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas: use different methods for interpolation and decorators or recurrence functions to improve computing time. Or we can create a seperate module decdicated to creating Kregging maps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deluge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
